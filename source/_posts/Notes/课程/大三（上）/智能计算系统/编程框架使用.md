---
title: 编程框架使用
categories:
  - Notes
  - 课程
  - 大三（上）
  - 智能计算系统
tags:
  - 智能计算系统
  - Pytorch
date:
---
深度学习编程框架：将深度学习算法中的基本操作封装成一系列组件，这一系列深度学习组件，即构成一套深度学习框架

### pytorch概述
##### 主要优点
简洁易懂：API设计简洁一致，基本上是tensor、autograd、nn三层封装
便于调试：采用动态图，可以进行调试
强大高效：提供了非常丰富的模型组件

#### pytorch和tensorflow
Tensorflow在工业界拥有完备的解决方案和用户基础
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231231234517.png)

### pytorch编程模型及基本用法
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231231234940.png)

#### Numpy基础
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116080600.png)
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116080608.png)
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116080629.png)

![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116080859.png)

#### ndarray的属性
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116081100.png)

#### 形状操作
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116081251.png)
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116081536.png)

#### 索引
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116081931.png)


### Pytorch基础
张量是现代深度学习框架的核心数据结构之一，包括PyTorch和TensorFlow等。它类似于 NumPy中的多维数组（ndarray），在PyTorch中，几乎所有的数据都表示为张量。这包括输 入数据、模型参数、梯度等。
支持GPU加速：PyTorch能够利用GPU加速计算，而张量是在GPU上进行计算的主要数据类 型。
张量是计算图上的数据载体，用张量统一表示所有的数据，张量在计算图的节点之间传递。
张量可以看做是n维的数组，数组的维数即为张量的阶数

#### tensor创建
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116082757.png)

#### tensor与array的转换
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116082837.png)

#### 张量的数据类型
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116083145.png)

不同数据分布对位宽的需求是不同的
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116083621.png)
不同层的数据对于位宽的需求是不一样的，每层数据都有其保持网络收敛的最低位宽要求，每层数据的位宽需求与数据分布之间存在关系

#### 张量属性的转换
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116084631.png)

#### 张量的数据格式
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116085711.png)

#### 张量的切片
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20240101105106.png)

#### 张量维度的压缩、扩展
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116090605.png)

#### 原地操作
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116091113.png)
原地操作能够节省内存占用，在进行深度学习算法推理时，使用原地操作能够有效减少模型占用的内存
原地操作会覆盖原张量，如果在模型训练时使用原地操 作来更新张量梯度，则每次迭代计算所的梯度值将被覆 盖，从而破坏模型的训练过程
对于多个张量同时引用一个张量的情况，对该张量进行 原地操作会影响其他张量的操作

#### 广播机制
对于参与计算操作的多个张量，如果张量维度不匹配，可以 使用PyTorch的广播机制对不匹配的张量维度进行扩展，最终 将这些张量均扩展为维度相同
广播条件：
- 每个张量都有至少1个维度
- 从**张量末尾的维度开始对齐**扩展，在对齐后的同一维度中，仅下列情况下才允许进行广播操作：1）维度尺寸相同；2）维度尺寸不同 但其中一个维度尺寸为1；3）其中一个张量没有该维度
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116091810.png)

#### 计算图
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20240101110110.png)
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20240101110417.png)

### 基于Pytorch的模型推理实现
#### 读取输入图像
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116093426.png)
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20231116093434.png)
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20240101110938.png)

#### 构建神经网络
![image.png](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20240101150707.png)

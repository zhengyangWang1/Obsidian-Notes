---
categories:
  - Notes
  - 课程
  - 神经网络与深度学习
title: 梯度放缓问题
date: 
tags:
  - 神经网络
---
### 激活函数


#### 梯度截断：防止梯度爆炸



#### 学习率衰减
- 余弦衰减：不引入任何参数
- 分段衰减
- 逆时衰减
- 指数衰减
- 自然指数衰减

#### 批量大小
批量的大小不影响随机梯度的期望，但是会影响随机梯度的方差
- 批量越大，随机梯度的方差越小，训练稳定，可以设置较大的学习率
- 批量越小，设置小的学习率

### 优化方法
#### 动量梯度下降法

#### RMSProp

#### Adam

### 参数初始化
#### 权重全零初始化

#### 使用较小的随机值初始化权重
从均值等于0，方差等于0.01的高斯分布中采样
```
W = 0.01 * np.random.randn(Din, Dout)
```
适合层数较少的神经网络

- Sigmoid或Tanh函数使用Xavier初始化
- relu使用kaiming初始化

### 损失函数
#### 交叉熵




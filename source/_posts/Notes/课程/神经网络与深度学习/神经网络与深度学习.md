---
title: 神经网络与深度学习
categories:
  - Notes
  - 课程
  - 神经网络与深度学习
update:
---
<u></u>教材：
- 神经网络与深度学习，邱锡鹏 [神经网络与深度学习](https://nndl.github.io/)
- 动手学深度学习 阿斯顿·张、李沐
- **深度学习，Ian Goddfellow**

公开课：
- 李宏毅：机器学习
- CS224n
- CS231n

考核：平时作业80（选够100分的题量）+其他20（随堂考试、问答）

---
### 神经网络

**激活函数：最关键部分**
- 激活函数：连续并可导的非线性函数
- 激活函数及其导函数要尽可能简单
- 激活函数的导函数要在一个合适的区间内
![](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20230921102752.png)

神经网络的要素：
- 拓扑结构：前馈网络，反馈网络，图网络。
前馈神经网络（FNN），循环神经网络（RNN）

- 网络的表示
- 学习算法

**前馈神经网络**：
一层的输出作用于下一层的输入
![](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20230921104850.png)![](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20230921104913.png)
向量表示：
![](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20230921105212.png)

**输出层**： 根据任务确定输出层的激活函数
- 回归任务：根据输出的值域选择激活函数
- 分类任务：softmax函数
![](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20230921110000.png)

**反向传播算法：**
![](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20230921110918.png)
J1为结果的误差，根据结果误差更新参数
![](https://cdn.jsdelivr.net/gh/zhengyangWang1/image@main/img/20230921111754.png)
需要会推导

均方误差会使深层的反向传播训练缓慢

神经网络具有通用近似性，只要神经元数量足够，可以拟合任何函数

非凸优化问题
梯度消失问题


